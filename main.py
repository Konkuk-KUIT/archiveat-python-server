import asyncio # [ì¶”ê°€] ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ëª¨ë“ˆ
import os
import logging
import sys

# ë¡œê¹… ì„¤ì •
# Uvicorn ì‹¤í–‰ ì‹œ ë¡œê·¸ê°€ ë³´ì´ì§€ ì•ŠëŠ” ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ stdout í•¸ë“¤ëŸ¬ ëª…ì‹œì  ì¶”ê°€
# ë£¨íŠ¸ ë¡œì»¤ì— í•¸ë“¤ëŸ¬ë¥¼ ì¶”ê°€í•˜ì—¬ services ë“± ëª¨ë“  ëª¨ë“ˆì˜ ë¡œê·¸ê°€ ì¶œë ¥ë˜ë„ë¡ í•¨
# root_logger = logging.getLogger()
# root_logger.setLevel(logging.INFO)

# # ê¸°ë³¸ í•¸ë“¤ëŸ¬ê°€ ì—†ì„ ê²½ìš°ì—ë§Œ ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
# if not root_logger.handlers:
#     handler = logging.StreamHandler(sys.stdout)
#     handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
#     root_logger.addHandler(handler)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)],
    force=True
)

logger = logging.getLogger(__name__)


# [ìˆ˜ì •] ì •ê·œí‘œí˜„ì‹ ëª¨ë“ˆ ì¶”ê°€
import re

def setup_cookies():
    """GitHub Secretsì—ì„œ ì „ë‹¬ëœ COOKIES_TXT í™˜ê²½ë³€ìˆ˜ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    í™˜ê²½ ë³€ìˆ˜ ì „ë‹¬ ê³¼ì •ì—ì„œ ê¹¨ì§„ íƒ­(\t)ì„ ë³µêµ¬í•˜ê³  Netscape í—¤ë”ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.
    """
    raw_content = os.getenv("COOKIES_TXT")
    cookie_path = os.path.abspath("cookies.txt")
    
    if raw_content:
        logger.info(f"ğŸª COOKIES_TXT found. Processing format... (Length: {len(raw_content)})")
        
        try:
            # 1. ë”°ì˜´í‘œ ë° ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
            content = raw_content.strip().strip('"').strip("'")
            
            lines = content.split('\\n') # í™˜ê²½ë³€ìˆ˜ì—ì„  ì¤„ë°”ê¿ˆì´ \\n ë¬¸ìë¡œ ë“¤ì–´ì˜¬ ìˆ˜ë„ ìˆìŒ
            if len(lines) == 1:
                 lines = content.split('\n') # ì‹¤ì œ ì¤„ë°”ê¿ˆì¼ ìˆ˜ë„ ìˆìŒ

            fixed_lines = []
            
            for line in lines:
                line = line.strip()
                # ë¹ˆ ì¤„ì´ë‚˜ ì£¼ì„ì€ ê·¸ëŒ€ë¡œ ë‘ 
                if not line or line.startswith('#'):
                    fixed_lines.append(line)
                    continue
                
                
                # [ê°œì„ ] ë¦¬í„°ëŸ´ \t ë¬¸ì ì²˜ë¦¬ (í™˜ê²½ë³€ìˆ˜ ì£¼ì… ì‹œ ì´ìŠ¤ì¼€ì´í”„ëœ ê²½ìš°)
                if '\\t' in line:
                    line = line.replace('\\t', '\t')
                
                # [ê°œì„ ] íƒ­ ê°œìˆ˜ê°€ ë¶€ì¡±í•˜ë©´(7ì»¬ëŸ¼ ê¸°ì¤€ 6ê°œ íƒ­ í•„ìš”) ìŠ¤í˜ì´ìŠ¤ ë³€í™˜ ì‹œë„
                if line.count('\t') < 6:
                    # ê³µë°±ì´ 2ê°œ ì´ìƒì¸ ë¶€ë¶„ì„ ì°¾ì•„ íƒ­ìœ¼ë¡œ ë°”ê¿‰ë‹ˆë‹¤.
                    # ë‹¨, ì´ë¯¸ íƒ­ì´ ìˆëŠ” ê²½ìš° ì„ì´ì§€ ì•Šë„ë¡ ì£¼ì˜ (ì—¬ê¸°ì„  íƒ­ì´ ë¶€ì¡±í•˜ë¯€ë¡œ ì‹œë„)
                    fixed_line = re.sub(r'\s{2,}', '\t', line)
                    if fixed_line.count('\t') >= 6:
                        line = fixed_line
                        
                fixed_lines.append(line)
            
            final_content = '\n'.join(fixed_lines)
            
            # 2. Netscape í—¤ë”ê°€ ì—†ìœ¼ë©´ ê°•ì œë¡œ ì¶”ê°€
            if not final_content.startswith('# Netscape'):
                final_content = "# Netscape HTTP Cookie File\n" + final_content
                
            with open(cookie_path, "w", encoding="utf-8") as f:
                f.write(final_content)
            
            logger.info(f"âœ… Created and fixed cookies.txt (Size: {len(final_content)} bytes)")
            
            # ê²€ì¦ìš©: ì²« ì¤„ ë‚´ìš© ë° Hex ê°’ ì¶œë ¥ (ì¸ì½”ë”©/íŠ¹ìˆ˜ë¬¸ì í™•ì¸ìš©)
            with open(cookie_path, "r", encoding="utf-8") as f:
                first_line = f.readline().strip()
                logger.info(f"   First line: {first_line[:100]}")
                logger.info(f"   First line HEX: {first_line[:50].encode('utf-8').hex(' ')}")
                logger.info(f"   First line: {first_line[:50]}...")
                
        except Exception as e:
            logger.error(f"âŒ Failed to create cookies.txt: {e}")
            # ì‹¤íŒ¨í•´ë„ ì¼ë‹¨ ì›ë³¸ì´ë¼ë„ ì €ì¥ ì‹œë„ (Fallback)
            try:
                with open(cookie_path, "w", encoding="utf-8") as f:
                    f.write(raw_content)
                logger.warning("âš ï¸ Saved raw content as cookies.txt due to processing error.")
            except:
                pass
    else:
        logger.warning("âš ï¸ COOKIES_TXT environment variable is missing. YouTube processing might fail.")

# [ìˆ˜ì • 3] ì„œë¹„ìŠ¤ ì„í¬íŠ¸ ë° ì´ˆê¸°í™” ì „ì— ì¿ í‚¤ ì„¤ì •ì„ ë¨¼ì € ì‹¤í–‰!!
setup_cookies()


from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from models import (
    SummarizeYoutubeRequest,
    SummarizeGenericRequest,
    SummarizeNaverNewsRequest,
    SummarizeTistoryRequest,
    SummarizeCollectionRequest,
    PythonSummaryResponse,
    CollectionSummaryResponse,
    HealthResponse,
    VideoInfo,
    ArticleInfo,
    Analysis,
    NewsletterSummaryBlock
)
from services.youtube import YouTubeProcessor
from services.summarizer import GeminiSummarizer
from services.naver_news import NaverNewsProcessor
from services.tistory import TistoryProcessor

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬(httpx ë“±) ë¡œê·¸ê°€ ë„ˆë¬´ ì‹œë„ëŸ¬ìš°ë©´ ë ˆë²¨ ì¡°ì •
logging.getLogger("httpx").setLevel(logging.WARNING)

app = FastAPI(
    title="Archiveat Python Server",
    description="LLM-powered content summarization service using Gemini AI",
    version="1.0.0"
)

# CORS ì„¤ì • - Java ì„œë²„ì—ì„œ í˜¸ì¶œ í—ˆìš©
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:8080", "http://localhost:3000", "http://127.0.0.1:8000", "http://localhost:8000"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” êµ¬ì²´ì ì¸ origin ì§€ì • ê¶Œì¥
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
# Whisper tiny ëª¨ë¸: ê°€ì¥ ë¹ ë¥¸ ìŒì„± ì¸ì‹ (ì •í™•ë„ëŠ” ë‚®ì§€ë§Œ ì†ë„ ìš°ì„ )
yt_processor = YouTubeProcessor(model_size="tiny")
summarizer = GeminiSummarizer()
naver_processor = NaverNewsProcessor()
tistory_processor = TistoryProcessor()


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return HealthResponse(
        status="healthy",
        message="Python server is running"
    )


@app.post("/api/v1/summarize/youtube", response_model=PythonSummaryResponse)
async def summarize_youtube(request: SummarizeYoutubeRequest):
    """
    YouTube URLì„ ë°›ì•„ ì˜ìƒ ì •ë³´ ì¶”ì¶œ ë° LLM ìš”ì•½ ìˆ˜í–‰
    
    ì²˜ë¦¬ ì‹œê°„: ì•½ 5-10ì´ˆ
    - YouTube ë°ì´í„° ì¶”ì¶œ: 2-3ì´ˆ
    - Gemini LLM ìš”ì•½: 3-7ì´ˆ
    """
    logger.info(f"Received YouTube summarization request: {request.url}")
    
    try:
        # 1. YouTube ë°ì´í„° ì¶”ì¶œ (Blocking -> Non-blocking)
        logger.info("Extracting YouTube data...")
        # [ìˆ˜ì •] ë™ê¸° í•¨ìˆ˜ì¸ yt_processor.processë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        video_data = await asyncio.to_thread(yt_processor.process, request.url)
        
        if "error" in video_data:
            logger.error(f"YouTube processing error: {video_data['error']}")
            raise HTTPException(status_code=400, detail=video_data["error"])
        
        # 2. Gemini AI ë¶„ì„ ë° ìš”ì•½ (Blocking -> Non-blocking)
        logger.info("Starting Gemini AI analysis...")
        # [ìˆ˜ì •] ë™ê¸° í•¨ìˆ˜ì¸ summarizer.summarize_contentë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        analysis_result = await asyncio.to_thread(
            summarizer.summarize_content,
            video_data["title"],
            (video_data.get("description") or "") + "\n" + (video_data.get("transcript") or "")
        )
        
        if "error" in analysis_result:
            logger.error(f"Gemini analysis error: {analysis_result['error']}")
            raise HTTPException(status_code=500, detail=f"LLM analysis failed: {analysis_result['error']}")
        
        # 3. ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        video_info = VideoInfo(
            title=video_data["title"],
            thumbnail_url=video_data["thumbnail_url"],
            content_url=request.url,
            channel=video_data["channel"],
            duration=video_data["duration"]
        )
        
        # ... (ìƒëµ) ...
        
        # newsletter_summaryë¥¼ Pydantic ëª¨ë¸ë¡œ ë³€í™˜
        newsletter_blocks = [
            NewsletterSummaryBlock(title=block.get("title", ""), content=block.get("content", ""))
            for block in analysis_result.get("newsletter_summary", [])
            if isinstance(block, dict)
        ]
        
        analysis = Analysis(
            category=analysis_result.get("category", "ê¸°íƒ€"),
            topic=analysis_result.get("topic", "ê¸°íƒ€"),
            small_card_summary=analysis_result.get("small_card_summary", ""),
            medium_card_summary=analysis_result.get("medium_card_summary", ""),
            newsletter_summary=newsletter_blocks
        )
        
        response = PythonSummaryResponse(
            video_info=video_info,
            analysis=analysis
        )
        
        logger.info(f"Successfully processed YouTube URL: {request.url}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"Unexpected error processing YouTube URL: {request.url}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")


@app.post("/api/v1/summarize/generic", response_model=PythonSummaryResponse)
async def summarize_generic(request: SummarizeGenericRequest):
    """
    ì¼ë°˜ í…ìŠ¤íŠ¸ ì½˜í…ì¸  ìš”ì•½ (í–¥í›„ í™•ì¥ìš©)
    """
    logger.info(f"Received generic summarization request: {request.title}")
    
    try:
        # Gemini AI ë¶„ì„ (Blocking -> Non-blocking)
        # [ìˆ˜ì •] ë³„ë„ ìŠ¤ë ˆë“œ ì‹¤í–‰
        analysis_result = await asyncio.to_thread(
            summarizer.summarize_content,
            request.title,
            request.content
        )
        
        if "error" in analysis_result:
            logger.error(f"Gemini analysis error: {analysis_result['error']}")
            raise HTTPException(status_code=500, detail=f"LLM analysis failed: {analysis_result['error']}")
        
        # ... (ìƒëµ) ...
        
        # newsletter_summaryë¥¼ Pydantic ëª¨ë¸ë¡œ ë³€í™˜
        newsletter_blocks = [
            NewsletterSummaryBlock(title=block["title"], content=block["content"])
            for block in analysis_result.get("newsletter_summary", [])
        ]
        
        analysis = Analysis(
            category=analysis_result.get("category", "ê¸°íƒ€"),
            topic=analysis_result.get("topic", "ê¸°íƒ€"),
            small_card_summary=analysis_result.get("small_card_summary", ""),
            medium_card_summary=analysis_result.get("medium_card_summary", ""),
            newsletter_summary=newsletter_blocks
        )
        
        response = PythonSummaryResponse(
            video_info=None,
            analysis=analysis
        )
        
        logger.info(f"Successfully processed generic content: {request.title}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"Unexpected error processing generic content: {request.title}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")


@app.post("/api/v1/summarize/naver-news", response_model=PythonSummaryResponse)
async def summarize_naver_news(request: SummarizeNaverNewsRequest):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ë˜ëŠ” ì¼ë°˜ ì›¹ ì½˜í…ì¸  ìš”ì•½
    """
    logger.info(f"Received Naver news summarization request: {request.url}")
    
    try:
        # 1. ì›¹ í¬ë¡¤ë§ (Blocking -> Non-blocking)
        logger.info("Crawling web content...")
        # [ìˆ˜ì •] ë³„ë„ ìŠ¤ë ˆë“œ ì‹¤í–‰
        crawl_result = await asyncio.to_thread(naver_processor.process, request.url)
        
        if crawl_result.get("error"):
            logger.error(f"Crawling error: {crawl_result['error']}")
            raise HTTPException(status_code=400, detail=f"Crawling failed: {crawl_result['error']}")
        
        # 2. Gemini AI ë¶„ì„ ë° ìš”ì•½ (Blocking -> Non-blocking)
        logger.info("Starting Gemini AI analysis...")
        
        content_with_memo = crawl_result["content"]
        if request.user_memo:
            content_with_memo = f"[ì‚¬ìš©ì ë©”ëª¨: {request.user_memo}]\n\n{content_with_memo}"
            logger.info(f"User memo provided: {request.user_memo}")
        
        # [ìˆ˜ì •] ë³„ë„ ìŠ¤ë ˆë“œ ì‹¤í–‰
        analysis_result = await asyncio.to_thread(
            summarizer.summarize_content,
            crawl_result["title"],
            content_with_memo
        )
        
        if "error" in analysis_result:
            logger.error(f"Gemini analysis error: {analysis_result['error']}")
            raise HTTPException(status_code=500, detail=f"LLM analysis failed: {analysis_result['error']}")
        
        # ... (ìƒëµ) ...
        
        # newsletter_summaryë¥¼ Pydantic ëª¨ë¸ë¡œ ë³€í™˜
        newsletter_blocks = [
            NewsletterSummaryBlock(title=block["title"], content=block["content"])
            for block in analysis_result.get("newsletter_summary", [])
        ]
        
        analysis = Analysis(
            category=analysis_result.get("category", "ê¸°íƒ€"),
            topic=analysis_result.get("topic", "ê¸°íƒ€"),
            small_card_summary=analysis_result.get("small_card_summary", ""),
            medium_card_summary=analysis_result.get("medium_card_summary", ""),
            newsletter_summary=newsletter_blocks
        )
        
        # article_info êµ¬ì„±
        article_info = ArticleInfo(
            title=crawl_result["title"],
            thumbnail_url=crawl_result.get("thumbnail_url"),
            content_url=request.url,
            word_count=len(crawl_result["content"])
        )
        
        response = PythonSummaryResponse(
            video_info=None,
            article_info=article_info,
            analysis=analysis
        )
        
        logger.info(f"Successfully processed Naver news: {request.url}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"Unexpected error processing Naver news: {request.url}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")


@app.post("/api/v1/summarize/tistory", response_model=PythonSummaryResponse)
async def summarize_tistory(request: SummarizeTistoryRequest):
    """
    Tistory ë¸”ë¡œê·¸ URLì„ ë°›ì•„ ë³¸ë¬¸ì„ ê¸ì–´ì˜¤ê³  Gemini AIë¡œ ìš”ì•½í•˜ì—¬ ì‘ë‹µ
    """
    logger.info(f"Received Tistory summarization request: {request.url}")

    try:
        # 1. Tistory í¬ë¡¤ë§ (Blocking -> Non-blocking)
        logger.info("Crawling Tistory content...")
        # [ìˆ˜ì •] ë³„ë„ ìŠ¤ë ˆë“œ ì‹¤í–‰
        crawl_result = await asyncio.to_thread(tistory_processor.process, request.url)

        if crawl_result.get("error"):
            logger.error(f"Tistory crawling error: {crawl_result['error']}")
            raise HTTPException(status_code=400, detail=f"Crawling failed: {crawl_result['error']}")

        # 2. Gemini AI ë¶„ì„ ë° ìš”ì•½ (Blocking -> Non-blocking)
        logger.info("Starting Gemini AI analysis...")

        content_with_memo = crawl_result["content"]
        if request.user_memo:
            content_with_memo = f"[ì‚¬ìš©ì ë©”ëª¨: {request.user_memo}]\n\n{content_with_memo}"
            logger.info(f"User memo provided: {request.user_memo}")

        # [ìˆ˜ì •] ë³„ë„ ìŠ¤ë ˆë“œ ì‹¤í–‰
        analysis_result = await asyncio.to_thread(
            summarizer.summarize_content,
            crawl_result["title"],
            content_with_memo
        )

        if "error" in analysis_result:
            logger.error(f"Gemini analysis error: {analysis_result['error']}")
            raise HTTPException(status_code=500, detail=f"LLM analysis failed: {analysis_result['error']}")

        # ... (ìƒëµ) ...

        # 3. ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        newsletter_blocks = [
            NewsletterSummaryBlock(title=block["title"], content=block["content"])
            for block in analysis_result.get("newsletter_summary", [])
        ]

        analysis = Analysis(
            category=analysis_result.get("category", "ê¸°íƒ€"),
            topic=analysis_result.get("topic", "ê¸°íƒ€"),
            small_card_summary=analysis_result.get("small_card_summary", ""),
            medium_card_summary=analysis_result.get("medium_card_summary", ""),
            newsletter_summary=newsletter_blocks
        )

        article_info = ArticleInfo(
            title=crawl_result["title"],
            thumbnail_url=crawl_result.get("thumbnail_url"),
            content_url=request.url,
            word_count=len(crawl_result["content"]),
        )

        response = PythonSummaryResponse(
            video_info=None,
            article_info=article_info,
            analysis=analysis
        )

        logger.info(f"Successfully processed Tistory: {request.url}")
        return response

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"Unexpected error processing Tistory: {request.url}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")


@app.post("/api/v1/summarize/collection", response_model=CollectionSummaryResponse)
async def summarize_collection(request: SummarizeCollectionRequest):
    """
    ì—¬ëŸ¬ ë‰´ìŠ¤ë ˆí„°ì˜ ì œëª©/ìš”ì•½ì„ ì…ë ¥ë°›ì•„ ì»¬ë ‰ì…˜ìš© íƒ€ì´í‹€(Small Card)ê³¼ ì„¤ëª…(Medium Card)ì„ ìƒì„±
    """
    logger.info(f"Received collection summarization request for {len(request.newsletters)} items")
    
    try:
        # Gemini AI ë¶„ì„ (Blocking -> Non-blocking)
        # [ìˆ˜ì •] ë³„ë„ ìŠ¤ë ˆë“œ ì‹¤í–‰
        analysis_result = await asyncio.to_thread(
            summarizer.summarize_collection,
            request.newsletters
        )
        
        if "error" in analysis_result:
            logger.error(f"Gemini analysis error: {analysis_result['error']}")
            raise HTTPException(status_code=500, detail=f"LLM analysis failed: {analysis_result['error']}")
        
        response = CollectionSummaryResponse(
            small_card_summary=analysis_result.get("small_card_summary", ""),
            medium_card_summary=analysis_result.get("medium_card_summary", "")
        )
        
        logger.info("Successfully processed collection summary")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.exception("Unexpected error processing collection summary")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, log_config=None)
